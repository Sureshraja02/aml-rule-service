server.port=7052
spring.datasource.enable=true
spring.session.store-type=none
spring.profiles.active=dev
server.undertow.threads.worker=500

spring.main.allow-bean-definition-overriding=true
spring.main.allow-circular-references=true
spring.banner.location=classpath:nanner.txt

#file watcher Related Config
file.directory.to.watch=C:/AML/AML-FILE-FOLDER/FILE-WATCHER/filewatch
csv.destination.folder=C:/AML/AML-FILE-FOLDER/FILE-WATCHER/filewatchcsvfile
processed.file.path=C:/AML/AML-FILE-FOLDER/FILE-WATCHER/filewatcherprocesed
from.file.format=.flt
to.file.format=.csv

file.watch.ismove=true
file.watch.isdelete=false
daily.cbs.file.count=21

aml.data.table.name=amldata
duckdb.file.path.url=jdbc:duckdb:
final.duckdb.file.path=C:/AML/AML-FILE-FOLDER/DUCKDB-FILE/


#//**********DUCK DATABASE ******************//
#spring.datasource.url=jdbc:duckdb:c:/AML_CUSTM_PROFILING.db
#spring.datasource.username=
#spring.datasource.password=
#spring.datasource.driver-class-name=org.duckdb.DuckDBDriver
#spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
#spring.jpa.properties.hibernate.format_sql=true
# JPA settings
#spring.jpa.hibernate.ddl-auto=none
#spring.jpa.show-sql=true
#spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.H2Dialect
#spring.jpa.properties.hibernate.temp.use_jdbc_metadata_defaults=false

# Disable sequence introspection
#spring.jpa.properties.hibernate.id.database_structure=none
#spring.jpa.properties.hibernate.id.sequence_support=false
#spring.jpa.properties.hibernate.id.new_generator_mappings=false


#//**********POSTGRESQL DATABASE []******************//
#spring.datasource.url=jdbc:postgresql://localhost:5432/AMLDB
#spring.datasource.username=amluser
#spring.datasource.password=amluser
#spring.datasource.driver-class-name=org.postgresql.Driver
#spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
#spring.jpa.properties.hibernate.format_sql=true
#spring.jpa.properties.hibernate.default_schema=amlschema


spring.datasource.url=jdbc:postgresql://aisworld.space:9000/fiuaml
spring.datasource.username=fiuaml
spring.datasource.password=FINaml@DO_GRES_25
spring.datasource.driver-class-name=org.postgresql.Driver
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.jpa.properties.hibernate.format_sql=false
spring.jpa.properties.hibernate.default_schema=amlschema

# Correct timezone property for HikariCP
spring.datasource.hikari.data-source-properties.TimeZone=Asia/Kolkata

# Optional Hibernate settings
spring.jpa.properties.hibernate.jdbc.time_zone=Asia/Kolkata


# JPA / Hibernate
spring.jpa.hibernate.ddl-auto=none
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect


# --- HikariCP Pool Settings (DuckDB is embedded, single connection only) ---
spring.datasource.hikari.pool-name=OracleHikariPool
# adjust based on DB limits
spring.datasource.hikari.maximum-pool-size=1
# keep a few idle connections
spring.datasource.hikari.minimum-idle=10
# 30s before idle connection is removed
spring.datasource.hikari.idle-timeout=60000
# 30s max wait for a connection
spring.datasource.hikari.connection-timeout=60000
# 30min max lifetime of a connection
spring.datasource.hikari.max-lifetime=1800000

# 5s timeout for validation
spring.datasource.hikari.validation-timeout=60000
spring.datasource.hikari.connection-test-query=SELECT 1

###Kafka Related Configurations Starting
spring.kafka.bootstrap-servers=127.0.0.1:9092
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.properties.spring.json.add.type.headers=false

spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.properties.spring.json.trusted.packages="*"

#spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.listener.ack-mode=manual
management.metrics.export.kafka.enabled=false

# Kafka Admin properties for topic configuration 
spring.kafka.admin.properties.retention.ms=60000
spring.kafka.admin.properties.cleanup.policy=delete


kafka.router.topic=routerkafatopic
kafka.reply.topic=routerkafatopicreply
kafka.group.id=router-result-grptest

server.inbound.topic=syncrequest
server.outbound.topic=syncresponse
server.inbound.sync.topic=syncrequest
server.outbound.sync.topic=syncresponse
latch.wait.time=40000


#Logging purpose
logging.level.root=WARN
logging.level.org.springframework.web=WARN
logging.level.org.hibernate=WARN
logging.level.org.springframework=WARN
logging.level.org.apache.http=DEBUG
logging.level.org.duckdb=DEBUG

http.disable.method=HEAD,OPTIONS,TRACE,TRACK,DELETE
spring.thymeleaf.check-template-location=false
spring.jpa.open-in-view=false

##AML CBS files prefix and table names.
aml.files.prefix.and.table.name=ACC~FS_ACCOUNT_DETAILS,ASA~FS_ACCOUNT_STATUS,ACT~FS_ACCOUNT_IMPORTS,BRN~FS_BRANCH,NCB~FS_CBWT_TRN_REPORT,CHQ~FS_CHEQUE,CNT~FS_CNTRY,CRM~FS_CURM,CST~FS_CUST,EOD~FS_EOD_BALANCES,INS~FS_INSTRUMENTS,JTH~FS_JTH,LCK~FS_LCKR,MCD~FS_MINOR,MAB~FS_MAB,NOM~FS_NOM,NCT~FS_NCUST,PRD~FS_PRD,TBM~FS_TBML_TRN,TTY~FS_TRANS_TYPE,TRN~FS_TRN

#File Fetch Interval Time Config
file.fetch.interval=6000

#File Coppied stauscheck config.
file.completion.check.interval=1000

#Csv import using these two mehtod - PGCopyManager OR JDBCCommon
csv.insert.copy.via=PGCopyManager

#Testing Purpose
aml.without.api.testing=false

#Cust base avg risk score
aml.cust.prof.avg.rsik.score=80

###Thread Executor Config
aml.rule.thread.executor.core.pool.size=32
aml.rule.thread.executor.max.pool.size=128
aml.rule.thread.executor.queue.capacity=2000
aml.rule.thread.executor.keep.alive.seconds=120
aml.rule.thread.executor.wait.terminate.seconds=60
aml.rule.thread.executor.complete.shutdown=true